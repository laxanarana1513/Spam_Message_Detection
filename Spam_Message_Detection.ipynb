{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "exceptional-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "import warnings\n",
    "import re\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sixth-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "msg = pd.read_csv(\"Cleaned_Dataset.csv\",  encoding='latin-1')\n",
    "msg.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "economic-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating target and features\n",
    "y = pd.DataFrame(msg.label)\n",
    "x = msg.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "white-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# countvectorization\n",
    "cv = CountVectorizer(max_features=5000)\n",
    "temp1 = cv.fit_transform(x['final_text'].values.astype('U')).toarray()\n",
    "tf = TfidfTransformer()\n",
    "temp1 = tf.fit_transform(temp1)\n",
    "temp1 = pd.DataFrame(temp1.toarray(), index=x.index)\n",
    "x = pd.concat([x, temp1], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "equipped-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop final_text col\n",
    "x.drop(['final_text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "transparent-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to int datatype\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intended-nigeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomforstclassifier model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fallen-flood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text: urgent week free membership Ã¥ prize jackpot txt word claim tc wwwdbuknet lccltd pobox ldnwarw\n"
     ]
    }
   ],
   "source": [
    "# User input\n",
    "text = input(\"Enter text: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "upset-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning/preprocessing - removing punctuation and digits\n",
    "updated_text = ''\n",
    "for i in range(len(text)):\n",
    "    if text[i] not in string.punctuation:\n",
    "        if text[i].isdigit() == False:\n",
    "            updated_text = updated_text+text[i]\n",
    "text = updated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "awful-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data clearning/preprocessing - tokenization and convert to lower case\n",
    "text = re.split(\"\\W+\", text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inside-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning/preprocessing - stopwords\n",
    "updated_list = []\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "for i in range(len(text)):\n",
    "    if text[i] not in stopwords:\n",
    "        updated_list.append(text[i])\n",
    "text = updated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "environmental-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning/preprocessing - lemmentizing\n",
    "updated_list = []\n",
    "wordlem = nltk.WordNetLemmatizer()\n",
    "for i in range(len(text)):\n",
    "    updated_list.append(wordlem.lemmatize(text[i]))\n",
    "text = updated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "olympic-racing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam\n"
     ]
    }
   ],
   "source": [
    "# data cleaning/preprocessing - mergining token\n",
    "text = \" \".join(text)\n",
    "\n",
    "text = cv.transform([text])\n",
    "text = tf.transform(text)\n",
    "pred = model.predict(text)\n",
    "if pred == 0:\n",
    "    print(\"Not Spam\")\n",
    "else:\n",
    "    print(\"Spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-silence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
